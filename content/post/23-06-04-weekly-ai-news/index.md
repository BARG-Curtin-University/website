---
title: Weekly AI News
date: 2023-06-04
image:
  focal_point: 'top'
---

In this week news, Google, Princeton and Standford work together to produce reusable tool for problem solving.  NVidia announced a supercomputer to be used for generative AI language applications and the Neurolangelo projet can turn 2D video clips int 3D structures and scenes.  OpenAI publises the 'lets verify step by step' approach.  Open source GPT4Tools aim to efficiently enable LLMs to decide and utilise different model for interaction with images.  Google, OpenAI and Anthropic create an model to evaluate extreme risks to help with alignment, responsible training, deployment and transparency.

<!--more-->


1.	Google, Princeton, and Stanford published a [paper](https://arxiv.org/pdf/2305.17126.pdf) “Large Language Models as Tool Makers”. The paper proposed a closed-loop framework referred to as LATMs, which can create their own reusable tools for problem-solving. The project uses GPT-3.5 as tool user, and GPT-4 as tool maker to reduce inference costs.
2.	Nvidia announced [DGX GH200](https://nvidianews.nvidia.com/news/nvidia-announces-dgx-gh200-ai-supercomputer), a supercomputer that is 10 times faster than the current fastest computer in the world. The computer will be used for generative AI language applications. Watch [this](https://www.nvidia.com/en-us/events/computex/) from 60mins for about 1 min. Google, Microsoft, and Meta will be its first users.
3.	Nvidia’s [Neuralangelo project](https://blogs.nvidia.com/blog/2023/06/01/neuralangelo-ai-research-3d-reconstruction/) can now turn 2D video clips into 3D structures and scenes. It literally generates detailed replicas of buildings, sculptures, and real objects from video clips taken on a mobile or camera.
4.	[Statement on AI Risk](https://www.safe.ai/statement-on-ai-risk) has been circulated and signed by a lot. “Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war”
5.	OpenAI publishes a research [paper](https://arxiv.org/abs/2305.20050), “let’s verify step by step”, by using this process supervision approach, the process-supervised model solves 78% of the problem from the MATH test set. It also aims at attack the Hallucination issues of LLMs.
6.	[GPT4Tools](https://github.com/StevenGrove/GPT4Tools) – an open-source tool based on Vicuan (LLaMA), and aims to efficiently enable LLMs to decide, control and utilizing different visual foundation models, allowing users to interact with images during a conversation.
7.	Google, OpenAI, Anthropic, etc published a [paper](https://arxiv.org/pdf/2305.15324.pdf) “Model evaluation for extreme risks”. An evaluation model is created to evaluate extreme risks by looking at dangerous capabilities and alignment as input and to ensure responsible training, responsible deployment, transparency and appropriate security.
