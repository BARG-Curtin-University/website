---
title: Weekli AI News
date: 2023-05-15
image:
  focal_point: 'top'
---

In this week news, Google introduced PaLM2, MIcorosoft announced more intererations in to office products, OpenAI release a model to produce 3D objects, HuggingFace announced a agent usese NLPand tools similar to LangCHain, Meta announced a AI model of using six modalities at once, OpenAI applied GPT-4 to automatically propose explanations for GPT-2 and IBM announced another LLM which uses principles to drive self alignment to minise human supervision.

<!--more-->

1.	[Google.io conference](https://developers.googleblog.com/2023/05/io23-developer-keynote-recap.html) – 1) Introduced PaLM v2 which support Google’s Bard, improved programming coding and dialog quality of Bard, support over 100 language translation, image <-> text generation/analysis, and more; 2) Google search supercharged with AGI, multi-round QA allows following-up question; 3) improved Gmail and Google photos features and others
2.	Anthropic’s [Claude](https://twitter.com/AnthropicAI/status/1656700154190389248?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Etweet) model can process 100K tokens now, more than 3X bigger than GPT-4’s 32K tokens.
3.	Microsoft [announced](https://www.microsoft.com/en-us/microsoft-365/blog/2023/05/09/introducing-the-microsoft-365-copilot-early-access-program-and-new-capabilities-in-copilot/) new capabilities in Copilot, including semantic index, copilot in whiteboard makes Teams meetings and brainstorms more creative and effective; integrate DALL.E  into PowerPoint to automatically generate ppt slides.
4.	OpenAI announced [Shape-E](https://github.com/openai/shap-e), a conditional generative model for 3D assets. Type in text prompts into Shape-E, and the model will produce 3D objects that create better more detailed, and accurate objects.
5.	HuggingFace announced [Transformers Agent](https://huggingface.co/docs/transformers/transformers_agents) – the agent provides a natural language API, which can interpret natural language and use a list of curated tools. The agent dramatically simplifies the process of a pre-trained LLM to call tools. A similar function with [LangChain](https://python.langchain.com/en/latest/index.html) – a framework for developing applications powered by LLM.
6.	Meta announced [ImageBind](https://twitter.com/MetaAI/status/1655989274620358656) – an AI model capable of binding data from six modalities at once, including the 3D shape of an image. [ImageBind](https://ai.facebook.com/blog/imagebind-six-modalities-binding-ai/) outperforms prior individually trained models and helps AI by enabling machines to better analyze many different forms of information together.
7.	OpenAI applied GPT-4 to automatically propose [explanations](https://twitter.com/OpenAI/status/1655982364273831936) for GPT-2’S 300K neurons, and found neurons responding to concepts like similes, “things done correctly”, or expressions of certainty. GitHub link.
8.	IBM announced [Dromedary](https://github.com/IBM/Dromedary), another LLM which uses principle-driven, self-alignment to minimize human supervision, and surpasses the performance of ChatGPT and Alpaca.
